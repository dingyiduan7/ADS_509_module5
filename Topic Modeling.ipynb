{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce2bb89",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 5.1: Topic Modeling\n",
    "\n",
    "This notebook holds Assignment 5.1 for Module 5 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In this assignment you will work with a categorical corpus that accompanies `nltk`. You will build the three types of topic models described in Chapter 8 of _Blueprints for Text Analytics using Python_: NMF, LSA, and LDA. You will compare these models to the true categories. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e2c06",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85bce08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dingyi Duan\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# These libraries may be useful to you\n",
    "\n",
    "#from nltk.corpus import brown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#import gensim\n",
    "#import gensim.corpora as corpora\n",
    "#from gensim.utils import simple_preprocess\n",
    "#from gensim.models import CoherenceModel,LdaMulticore, Phrases \n",
    "#from gensim.models.phrases import Phraser \n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb9257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "494de237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function comes from the BTAP repo.\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a901c",
   "metadata": {},
   "source": [
    "## Getting to Know the Brown Corpus\n",
    "\n",
    "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "457c59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adventure we have 29 articles.\n",
      "For belles_lettres we have 75 articles.\n",
      "For editorial we have 27 articles.\n",
      "For fiction we have 29 articles.\n",
      "For government we have 30 articles.\n",
      "For hobbies we have 36 articles.\n",
      "For humor we have 9 articles.\n",
      "For learned we have 80 articles.\n",
      "For lore we have 48 articles.\n",
      "For mystery we have 24 articles.\n",
      "For news we have 44 articles.\n",
      "For religion we have 17 articles.\n",
      "For reviews we have 17 articles.\n",
      "For romance we have 29 articles.\n",
      "For science_fiction we have 6 articles.\n"
     ]
    }
   ],
   "source": [
    "# categories of articles in Brown corpus\n",
    "for category in brown.categories() :\n",
    "    print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fb133c",
   "metadata": {},
   "source": [
    "Let's create a dataframe of the articles in of hobbies, editorial, government, news, and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18f50b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['editorial','government','news','romance','hobbies'] \n",
    "\n",
    "category_list = []\n",
    "file_ids = []\n",
    "texts = []\n",
    "\n",
    "for category in categories : \n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "        \n",
    "        # build some lists for a dataframe\n",
    "        category_list.append(category)\n",
    "        file_ids.append(file_id)\n",
    "        \n",
    "        text = brown.words(fileids=file_id)\n",
    "        texts.append(\" \".join(text))\n",
    "\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['category'] = category_list\n",
    "df['id'] = file_ids\n",
    "df['text'] = texts \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3a6fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    category    id                                               text\n",
      "0  editorial  cb01  Assembly session brought much good The General...\n",
      "1  editorial  cb02  Must Berlin remain divided ? ? The inference h...\n",
      "2  editorial  cb03  A good man departs . Goodby , Mr. Sam . Sam Ra...\n",
      "3  editorial  cb04  A shock wave from Africa Word of Dag Hammarskj...\n",
      "4  editorial  cb05  Help when needed If the Dominican Republic ach...\n",
      "\n",
      "\n",
      "\n",
      "[news          44\n",
      "hobbies       36\n",
      "government    30\n",
      "romance       29\n",
      "editorial     27\n",
      "Name: category, dtype: int64, cb21    1\n",
      "ch26    1\n",
      "cb15    1\n",
      "ce13    1\n",
      "ca24    1\n",
      "       ..\n",
      "ch23    1\n",
      "cb11    1\n",
      "cp24    1\n",
      "ch05    1\n",
      "cb07    1\n",
      "Name: id, Length: 166, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "# check out the dataframe\n",
    "print(df.head())\n",
    "print('\\n\\n')\n",
    "print([df[i].value_counts() for i in df.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "586f47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some helpful columns on the df\n",
    "df['char_len'] = df['text'].apply(len)\n",
    "df['word_len'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2128fd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.groupby('category').agg({'word_len': 'mean'}).plot.bar(figsize=(10,6), rot = 0) # better for my neck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ffeb5",
   "metadata": {},
   "source": [
    "Now do our TF-IDF and Count vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21a7d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df and max_df: int for abs. count and float for %\n",
    "count_text_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5, max_df=0.7) \n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df[\"text\"])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f7ab4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4931</th>\n",
       "      <th>4932</th>\n",
       "      <th>4933</th>\n",
       "      <th>4934</th>\n",
       "      <th>4935</th>\n",
       "      <th>4936</th>\n",
       "      <th>4937</th>\n",
       "      <th>4938</th>\n",
       "      <th>4939</th>\n",
       "      <th>4940</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows Ã— 4941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  4931  \\\n",
       "0       0     3     0     0     0     0     0     1     0     1  ...     0   \n",
       "1       0     3     0     0     0     1     0     1     0     0  ...     0   \n",
       "2       0     0     0     2     0     0     0     0     0     0  ...     0   \n",
       "3       0     1     0     0     0     2     0     0     0     1  ...     0   \n",
       "4       0     1     0     1     1     0     0     0     0     0  ...     0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "161     0     0     0     0     0     0     0     0     0     1  ...     0   \n",
       "162     0     2     0     0     0     0     0     0     1     2  ...     0   \n",
       "163     0     0     4     1     0     0     1     0     0     0  ...     0   \n",
       "164     0     8     1     1     0     1     1     0     0     1  ...     0   \n",
       "165    11     0     2     0     0     2     0     0     1     0  ...     0   \n",
       "\n",
       "     4932  4933  4934  4935  4936  4937  4938  4939  4940  \n",
       "0       0     0     1     0     0     0     0     0     0  \n",
       "1       0     0     3     0     0     0     0     2     0  \n",
       "2       0     0     0     2     0     0     0     0     0  \n",
       "3       0     1     0     0     0     0     0     0     0  \n",
       "4       0     0     0     0     0     0     0     0     0  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "161     0     0     0     0     0     0     0     0     0  \n",
       "162     0     0     3     0     0     0     0     0     0  \n",
       "163     0     0     0     0     0     0     0     0     0  \n",
       "164     0     0     0     0     0     0     0     0     0  \n",
       "165     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[166 rows x 4941 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_text_vectors.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "875deba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4941)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a8f57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4931</th>\n",
       "      <th>4932</th>\n",
       "      <th>4933</th>\n",
       "      <th>4934</th>\n",
       "      <th>4935</th>\n",
       "      <th>4936</th>\n",
       "      <th>4937</th>\n",
       "      <th>4938</th>\n",
       "      <th>4939</th>\n",
       "      <th>4940</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039797</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>0.012368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083169</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.288618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows Ã— 4941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    0.000000  0.046852  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.000000  0.040107  0.000000  0.000000  0.000000  0.015896  0.000000   \n",
       "2    0.000000  0.000000  0.000000  0.041794  0.000000  0.000000  0.000000   \n",
       "3    0.000000  0.016735  0.000000  0.000000  0.000000  0.039797  0.000000   \n",
       "4    0.000000  0.014687  0.000000  0.018843  0.019635  0.000000  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "161  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "162  0.000000  0.027690  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "163  0.000000  0.000000  0.037145  0.012368  0.000000  0.000000  0.022478   \n",
       "164  0.000000  0.083169  0.010015  0.013338  0.000000  0.012361  0.024242   \n",
       "165  0.288618  0.000000  0.021679  0.000000  0.000000  0.026758  0.000000   \n",
       "\n",
       "         7         8         9     ...  4931  4932      4933      4934  \\\n",
       "0    0.023450  0.000000  0.019456  ...   0.0   0.0  0.000000  0.016895   \n",
       "1    0.020074  0.000000  0.000000  ...   0.0   0.0  0.000000  0.043389   \n",
       "2    0.000000  0.000000  0.000000  ...   0.0   0.0  0.000000  0.000000   \n",
       "3    0.000000  0.000000  0.020849  ...   0.0   0.0  0.036429  0.000000   \n",
       "4    0.000000  0.000000  0.000000  ...   0.0   0.0  0.000000  0.000000   \n",
       "..        ...       ...       ...  ...   ...   ...       ...       ...   \n",
       "161  0.000000  0.000000  0.011308  ...   0.0   0.0  0.000000  0.000000   \n",
       "162  0.000000  0.018709  0.034496  ...   0.0   0.0  0.000000  0.044933   \n",
       "163  0.000000  0.000000  0.000000  ...   0.0   0.0  0.000000  0.000000   \n",
       "164  0.000000  0.000000  0.012951  ...   0.0   0.0  0.000000  0.000000   \n",
       "165  0.000000  0.015205  0.000000  ...   0.0   0.0  0.000000  0.000000   \n",
       "\n",
       "         4935  4936  4937  4938      4939  4940  \n",
       "0    0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "1    0.000000   0.0   0.0   0.0  0.062348   0.0  \n",
       "2    0.034956   0.0   0.0   0.0  0.000000   0.0  \n",
       "3    0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "4    0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "..        ...   ...   ...   ...       ...   ...  \n",
       "161  0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "162  0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "163  0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "164  0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "165  0.000000   0.0   0.0   0.0  0.000000   0.0  \n",
       "\n",
       "[166 rows x 4941 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_text_vectors.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1062b21",
   "metadata": {},
   "source": [
    "Q: What do the two data frames `count_text_vectors` and `tfidf_text_vectors` hold? \n",
    "\n",
    "A: The `count_text_vectors` holds the absolute counts for each word in different corpura while the TfidfTransformer (`tfidf_text_vectors`) transforms this count matrix to a normalized tf or tf-idf representation in float format (percentage)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c3f94",
   "metadata": {},
   "source": [
    "## Fitting a Non-Negative Matrix Factorization Model\n",
    "\n",
    "In this section the code to fit a five-topic NMF model has already been written. This code comes directly from the [BTAP repo](https://github.com/blueprints-for-text-analytics-python/blueprints-text), which will help you tremendously in the coming sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28745a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_text_model = NMF(n_components=5, random_state=314)\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67185e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee51e9b",
   "metadata": {},
   "source": [
    "Now some work for you to do. Compare the NMF factorization to the original categories from the Brown Corpus.\n",
    "\n",
    "We are interested in the extent to which our NMF factorization agrees or disagrees with the original categories in the corpus. For each topic in your NMF model, tally the Brown categories and interpret the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d4e2bc",
   "metadata": {},
   "source": [
    "Q: How does your five-topic NMF model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e37cb5",
   "metadata": {},
   "source": [
    "## Fitting an LSA Model\n",
    "\n",
    "In this section, follow the example from the repository and fit an LSA model (called a \"TruncatedSVD\" in `sklearn`). Again fit a five-topic model and compare it to the actual categories in the Brown corpus. Use the TF-IDF vectors for your fit, as above. \n",
    "\n",
    "To be explicit, we are once again interested in the extent to which this LSA factorization agrees or disagrees with the original categories in the corpus. For each topic in your model, tally the Brown categories and interpret the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b53d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94d56f",
   "metadata": {},
   "source": [
    "Q: How does your five-topic LSA model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call display_topics on your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b280a",
   "metadata": {},
   "source": [
    "Q: What is your interpretation of the display topics output? \n",
    "\n",
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4d29",
   "metadata": {},
   "source": [
    "## Fitting an LDA Model\n",
    "\n",
    "Finally, fit a five-topic LDA model using the count vectors (`count_text_vectors` from above). Display the results using `pyLDAvis.display` and describe what you learn from that visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802cb8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit your LDA model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call `display_topics` on your fitted model here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c67876",
   "metadata": {},
   "source": [
    "Q: What inference do you draw from the displayed topics for your LDA model? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n",
    "Q: Repeat the tallying of Brown categories within your topics. How does your five-topic LDA model compare to the original Brown categories? \n",
    "\n",
    "A: <!-- Your answer here --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.sklearn.prepare(lda_text_model, count_text_vectors, count_text_vectorizer, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d14c87",
   "metadata": {},
   "source": [
    "Q: What conclusions do you draw from the visualization above? Please address the principal component scatterplot and the salient terms graph.\n",
    "\n",
    "A: <!-- Your answer here --> \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
